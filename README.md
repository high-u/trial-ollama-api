# README

## Ollama API

### ホスト

```
http://localhost:11434
```

### タグ一覧の取得

```
GET /api/tags
```

### 生成

```
POST /api/generate
```

- パラメータ
    - model: (必須)モデル名
    - prompt: 応答を生成するためのプロンプト
    - suffix: モデル応答の後のテキスト
    - images: (オプション) base64でエンコードされた画像のリスト（ などのマルチモーダルモデル用llava）
- 詳細パラメータ（オプション）:
    - format: レスポンスを返す形式。形式はjsonJSONスキーマまたは
    - options:モデルファイルのドキュメントに記載されている追加のモデルパラメータ、例えばtemperature
    - system: システムメッセージ ( で定義されているものを上書きしますModelfile)
    - template: 使用するプロンプトテンプレート（ で定義されているものを上書きしますModelfile）
    - stream:falseレスポンスがオブジェクトのストリームではなく、単一のレスポンスオブジェクトとして返される場合
    - rawtrue:プロンプトに書式設定が適用されない場合。APIrawへのリクエストで完全なテンプレート プロンプトを指定する場合は、このパラメータを使用することもできます。
    - keep_alive: リクエスト後にモデルがメモリにロードされたままになる時間を制御します (デフォルト: 5m)
    - context(非推奨): への以前のリクエストから返されたコンテキストパラメータ/generate。これは短い会話メモリを保持するために使用できます。
